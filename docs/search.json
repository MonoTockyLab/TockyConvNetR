[{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/Introduction.html","id":"introduction-to-tockymachinelearning-package-suite","dir":"Articles","previous_headings":"","what":"1. Introduction to TockyMachineLearning Package Suite","title":"Introduction to Tocky ConvNet Analysis","text":"TockyRandomForest R package part TockyMachineLearning package suite. TockyMachineLearning package suite comprises several subpackages designed facilitate advanced machine learning analyses flow cytometric data Fluorescent Timer reporters. package within suite specializes different aspects data handling analysis: TockyRandomForest: R package provides ConvNet analysis tools specifically tailored processing interpreting Fluorescent Timer data. TockyConvNetR: R package focused data preprocessing feature cell analysis suitable Convolutional Neural Network (ConvNet) analyses. package facilitates image conversion methods preparing Tocky data implements Inverse GradCAM Gating Analysis interpret ConvNet/Grad-CAM outputs. TockyConvNetPy: Python package dedicated performing ConvNet training conducting Grad-CAM analysis, complementing R-based preprocessing analysis tools. schematic figure providing overview workflows interactions within TockyMachineLearning suite.  Tocky short “Timer--cell-kinetics--activity,” inspired Japanese word “toki,” meaning “time.” serves comprehensive toolkit integrates experimental computational approaches analyze temporal dynamics cell differentiation activation vivo.","code":""},{"path":[]},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/Introduction.html","id":"the-use-of-fluorescent-timer-protein-for-investigating-cellular-dynamics","dir":"Articles","previous_headings":"2. Principles of Tocky","what":"2-1. The Use of Fluorescent Timer Protein for Investigating Cellular Dynamics","title":"Introduction to Tocky ConvNet Analysis","text":"concept Tocky technology conceived created Dr. Masahiro Ono. measure time-dependent processes individual T cells vivo, Dr. Ono envisioned using substance capable encoding time information known kinetics. screening experiments, mCherry mutant, Fluorescent Timer protein Fast-FT, originally developed Verkhusha group Einstein (Subach et al. (2009)), emerged ideal candidate, particularly compatibility flow cytometry. Leveraging feature, Ono lab developed new Fluorescent Timer reporter transgenic mouse strains analyzing T cell activities differentiation vivo. new transgenic strains include Nr4a3 Fluorescent Timer reporter mice Nr4a3 gene, downstream T cell receptor signaling, Foxp3 gene, specific regulatory T cells. effectively analyze data generated Tocky mice, Dr. Ono developed data analytic concepts dedicated Fluorescent Timer data, using Trigonometric Transformation method analyzing Fluorescent Timer data, reported 2018 (Bending, Martin, et al. (2018)). Consequently, novel Fluorescent Timer systems analysis temporal changes molecular cellular activities designated Nr4a3-Tocky Foxp3-Tocky.  Fluorescent Timer protein undergoes spontaneous irreversible transition emission spectrum, shifting blue red fluorescence post-translation. experimental measurements fluorescence revealed half-life Timer Blue fluorescence approximately 4 hours, whereas half-life Timer Red fluorescence extends 120 hours (Bending, Martin, et al. (2018)).","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/Introduction.html","id":"tocky-data-transformation","dir":"Articles","previous_headings":"2. Principles of Tocky","what":"2-2. Tocky Data Transformation","title":"Introduction to Tocky ConvNet Analysis","text":"primary objective Tocky approach analyze time-related information captured profiles Timer-Blue Timer-Red fluorescence data individual cell level. optimally utilize temporal information single-cell analysis, introduced novel concept along appropriate algorithms. tools designed normalize transform Timer fluorescence data two key metrics: Timer Angle Timer Intensity. Timer Angle defined angle (degrees, ranging 0 90) measured Timer-Blue axis towards Timer-Red axis. Timer Intensity represents distance (norm) cell origin (Timer-Blue = Timer-Red = 0). Normalized trigonometric-transformed Timer fluorescence data offer opportunities analyze real-time transcriptional activities cumulative (historical) activities observed days leading experimental analysis cells, demonstrated previous reports (Bending, Martin, et al. (2018); Bending, Paduraru, et al. (2018)).","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/Introduction.html","id":"data-preprocessing","dir":"Articles","previous_headings":"","what":"3. Data Preprocessing","title":"Introduction to Tocky ConvNet Analysis","text":"Install use TockyPrep R package preprocess flow cytometric Fluorescent Timer data (Ono (2024)).","code":""},{"path":[]},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"introduction-to-fluorescent-timer-and-the-tocky-system","dir":"Articles","previous_headings":"","what":"Introduction to Fluorescent Timer and the Tocky System","title":"Getting Started with TockyConvNetR Analysis","text":"Fluorescent Timer proteins change emission spectra time, serving powerful tools monitoring transcriptional dynamics vivo. recent efforts successfully implemented data preprocessing methods TockyPrep package (Ono (2024b), Ono (2025)). Additionally, analyze Timer fluorescence dynamics apply quantitative statistical analysis methods, developed TockyLocus package (Ono (2024a)). However, analyzing complex Timer profiles, typically seen flow cytometric data Foxp3-Tocky mice, remains challenging. Aim overcome challenges, applying machine learning methods represents attractive approach. package suite, TockyMachineLearning, provides comprehensive methods identifying feature cells represent group-specific features Timer profiles. Specifically, current TockyConvNetR package offers Random Forest methods developed analyzing flow cytometric Fluorescent Timer data.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"relationship-to-the-packages-tockyprep-and-tockylocus","dir":"Articles","previous_headings":"","what":"Relationship to the Packages TockyPrep and TockyLocus","title":"Getting Started with TockyConvNetR Analysis","text":"TockyPrep package designed facilitate data preprocessing flow cytometric Fluorescent Timer data. Subsequently, TockyLocus package leverages preprocessed data apply data categorization methods, enabling quantitative analysis Timer Angle data (Bending et al. (2018)). However, approach applicable one-dimensional data . TockyConvNetR package utilizes special object class TockyPrepData provided TockyPrep package perform machine learning analysis","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"install-tockyconvnetr","dir":"Articles","previous_headings":"","what":"Install TockyConvNetR","title":"Getting Started with TockyConvNetR Analysis","text":"begin using TockyConvNetR, need install TockyConvNetR TockyPrep packages GitHub:","code":"# Install TockyPrep and TockyConvNetR from GitHub devtools::install_github(\"MonoTockyLab/TockyPrep\") devtools::install_github(\"MonoTockyLab/TockyConvNetR\")"},{"path":[]},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"identifying-cns2-dependent-foxp3-transcriptional-dynamics","dir":"Articles","previous_headings":"Sample Workflow","what":"Identifying CNS2-dependent Foxp3 transcriptional dynamics","title":"Getting Started with TockyConvNetR Analysis","text":"section guides analyzing flow cytometric data cells expressing Fluorescent Timer proteins. example workflow, aim identify CNS2-dependent transcription dynamics Foxp3-Tocky mice. Ensure : Training Data: Analyzing Fluorescent Timer reporter activity using flow cytometry. Independent Test Data: Separate dataset validation purposes. Preprocessed data analysis methods provided via TockyPrep package’s TockyPrepData class. Load example data included TockyConvNetR: loads two datasets: training data train_x test data test_y, obtained flow cytometric analysis WT Foxp3 Tocky mice CNS2 KO Foxp3 Tocky mice. Foxp3 Tocky mice WT Foxp3 Tocky mice: mice carry Foxp3-Timer transgene, synchronously expresses Fluorescent Timer (specifically Fast-FT) alongside Foxp3 transcription. CNS2 KO Foxp3 Tocky mice: mice, Conserved Non-coding Sequence (CNS), specifically CNS2 Foxp3 gene, approximately 500 base pairs length, deleted Foxp3-Timer transgene using CRISPR technology. dataset generated analyzing T-cells Foxp3-Tocky mice (WT) CRISPR-mediated Foxp3-Tocky mutants, specifically CNS2KO Foxp3-Tocky mice (KO). aim identify CNS2-dependent Foxp3 transcription dynamics Timer space data-oriented manner.","code":"library(TockyPrep) library(TockyConvNetR) file_path <- system.file(\"extdata\", package = \"TockyConvNetR\") filenames <- list.files(path = file_path, pattern = 'rda') files <- file.path(file_path, filenames) for(i in files){load(i)} #The summary of the training data, train_x show(train_x) ## TockyPrepData Object: ## Total cell number: 1804517  ## Variables:  file, Angle, Intensity, FSC.A, Timer.Blue, Timer.Red  ## Total sample number: 34  ## Groups:  KO, WT #The summary of the test data, test_y show(test_y) ## TockyPrepData Object: ## Total cell number: 1974400  ## Variables:  file, Angle, Intensity, FSC.A, Timer.Blue, Timer.Red  ## Total sample number: 49  ## Groups:  KO, WT"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"image-conversion-for-tocky-convnet-modelling","dir":"Articles","previous_headings":"Sample Workflow","what":"Image Conversion for Tocky ConvNet Modelling","title":"Getting Started with TockyConvNetR Analysis","text":"Convert TockyPrep data 100x100 resolution images training: conversion creates train_images test_images directories containing labeled training sample data Python-based modeling TockyConvNetPy. Now proceed TockyConvNetPy analysis using Python Keras!","code":"train_x <- ImageConversion(train_x, output = 'train_images') test_y <- ImageConversion(test_y, output = 'test_images')"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"inverse-image-conversion-for-analysing-grad-cam-output","dir":"Articles","previous_headings":"Sample Workflow","what":"Inverse Image Conversion for Analysing Grad-CAM Output","title":"Getting Started with TockyConvNetR Analysis","text":"successfully training TockyCNN model python, analyze output Gradient-weighted Class Activation Mapping (Grad-CAM): current vignette, use pre-analysed TockyCNN Grad-CAM output TockyConvNetPy. Import Grad-CAM output csv file: Use inverseGradCAM map Grad-CAM data, 100 x 100 image data, original cytometry data: Visualize Grad-CAM within Timer fluorescence space:  T cells exhibiting WT Foxp3 Tocky-specific features represented warm colors (red), whereas related CNS2 KO Foxp3 Tocky depicted cool colors (blue). Thus function plotInverseGradCAM facilitates identification cells CNS2-dependent Foxp3 transcription dynamics. compare inverse Grad-CAM plot original Fluorescent Timer data, use function plot_tocky package TockyPrep.  shows T cells analysed test dataset.","code":"csv_filename <- list.files(path = file_path, pattern = 'csv') file_csv <- file.path(file_path, csv_filename) gradcam_heatmap <- read.csv(file_csv) feature_cells <- inverseGradCAM(x = test_y, feature_matrix = gradcam_heatmap, mode = 'gating', ncol =2, nrow = 1) feature_cells <- inverseGradCAM(x = test_y, feature_matrix = gradcam_heatmap, mode = 'gating', ncol =2, nrow = 1, percentile = 0.75) plotInverseGradCAM(x = test_y, feature_matrix = gradcam_heatmap, xlim = c(1.5,5), ylim = c(1.5,5)) # Visualizing the original flow cytometric Fluorescent Timer data plot_tocky(test_y, interactive = FALSE, save = FALSE, n = 2,verbose = FALSE)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"analysis-of-feature-cells-identified-by-grad-cam","dir":"Articles","previous_headings":"Sample Workflow","what":"Analysis of Feature Cells Identified by Grad-CAM","title":"Getting Started with TockyConvNetR Analysis","text":"characterise CNS2-dependent Foxp3 transcription, analyse properties Grad-CAM feature cells identified inverseGradCAM. Utilize plotGradCAMFeatureCells function quantitatively assess abundance feature cells identified TockyCNN model.  plotGradCAMFeatureMFI function employed measure Mean Fluorescence Intensity (MFI) specific markers within feature cells, well Timer-positive Timer-negative cells.  measurement provides insights expression levels markers, associated CNS2-dependent Foxp3 transcirptional activities.","code":"plotGradCAMFeatureCells(x = test_y, feature_cells) ## Warning: `position_dodge()` requires non-overlapping x ## intervals. plotGradCAMFeatureMFI(x = test_y, feature_cells)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/articles/TockyConvNetRanalysis.html","id":"final-notes","dir":"Articles","previous_headings":"Sample Workflow","what":"Final Notes","title":"Getting Started with TockyConvNetR Analysis","text":"TockyConvNet component comprehensive TockyMachineLearning package suite, designed support advanced machine learning analyses Tocky studies. Explore packages within suite fully leverage potential datasets!","code":""},{"path":[]},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Masahiro Ono. Author, maintainer.           0000-0002-9284-7326","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ono M (2025). TockyConvNetR: Convolutional Neural Network-Based Machine Learning Methods Analyzing Flow Cytometric Fluorescent Timer Data. R package version 0.1.0, https://github.com/MonoTockyLab/TockyMachineLearning/TockyConvNetR.","code":"@Manual{,   title = {TockyConvNetR: Convolutional Neural Network-Based Machine Learning Methods for Analyzing Flow Cytometric Fluorescent Timer Data},   author = {Masahiro Ono},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/MonoTockyLab/TockyMachineLearning/TockyConvNetR}, }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/index.html","id":"tockyconvnetr-machine-learning-r-package-for-flow-cytometric-fluorescent-timer-analysis-beta-version","dir":"","previous_headings":"","what":"Convolutional Neural Network-Based Machine Learning Methods for Analyzing Flow Cytometric Fluorescent Timer Data","title":"Convolutional Neural Network-Based Machine Learning Methods for Analyzing Flow Cytometric Fluorescent Timer Data","text":"Author: Dr Masahiro OnoDate: 28 January 2025  TockyConvNetR R package part TockyMachineLearning package suite. TockyMachineLearning package suite comprises several subpackages designed facilitate advanced machine learning analyses flow cytometric data Fluorescent Timer reporters. package within suite specializes different aspects data handling analysis: TockyRandomForest: R package provides Random Forest analysis tools specifically tailored processing interpreting Fluorescent Timer data. TockyConvNetR: R package focused data preprocessing feature cell analysis suitable Convolutional Neural Network (ConvNet) analyses. package facilitates image conversion methods preparing Tocky data implements Inverse GradCAM Gating Analysis interpret ConvNet/Grad-CAM outputs. TockyConvNetPy: Python package dedicated performing ConvNet training conducting Grad-CAM analysis, complementing R-based preprocessing analysis tools. schematic figure providing overview workflows interactions within TockyMachineLearning suite.","code":""},{"path":[]},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/ImageConversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Image Conversion for Direct Export of Samples — ImageConversion","title":"Image Conversion for Direct Export of Samples — ImageConversion","text":"Image Conversion Direct Export Samples","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/ImageConversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Image Conversion for Direct Export of Samples — ImageConversion","text":"","code":"ImageConversion(x, n_resolution = 100, selected_markers = NULL, output = NULL)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/ImageConversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Image Conversion for Direct Export of Samples — ImageConversion","text":"x TockyPrepData object n_resolution number bins used. default 100, .e. resolution output images 100 x 100. selected_markers character vector length two defining  marker data converted 2D images. output character specify output directory.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/ImageConversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Image Conversion for Direct Export of Samples — ImageConversion","text":"updated TockyPrepData object. addition, function exports image data numpy array files, used TockyMLPy analysis TockyCNN model construction.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/ImageConversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Image Conversion for Direct Export of Samples — ImageConversion","text":"","code":"if (FALSE) { # \\dontrun{ x <- ImageConversion(x, n_resolution = 100) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/convert_to_image.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Data to Image Matrices — convert_to_image","title":"Convert Data to Image Matrices — convert_to_image","text":"function processes dataset containing multiple subsets, identified unique 'file' identifier, converts subset matrix based binned 'Angle' 'Intensity' values. ensures consistent binning across subsets using global minimum maximum values, facilitating direct comparison resulting matrices.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/convert_to_image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Data to Image Matrices — convert_to_image","text":"","code":"convert_to_image(data, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/convert_to_image.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Data to Image Matrices — convert_to_image","text":"data data frame list data frames containing least three columns: 'file' (unique identifier subset), 'Angle', 'Intensity'. row represents observation specific angle intensity value. n_resolution number bins","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/convert_to_image.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Data to Image Matrices — convert_to_image","text":"list containing:   - matrices_list: list element data frame corresponding subset identified 'file', containing original data.   - bin_edges_Angle: Numeric vector bin edges used 'Angle' dimension.   - bin_edges_Intensity: Numeric vector bin edges used 'Intensity' dimension.   - counts_list: list matrices matrix represents binned counts 'Angle' 'Intensity' subset.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/convert_to_image.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Data to Image Matrices — convert_to_image","text":"","code":"if (FALSE) { # \\dontrun{ # Assume 'data' is your dataset containing 'file', 'Angle', and 'Intensity' columns result <- convert_to_image(data)  # Access the binned counts matrix for the first file first_counts_matrix <- result$counts_list[[1]]  # Plot the matrix as an image image(result$bin_edges_Angle, result$bin_edges_Intensity, first_counts_matrix) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/dot-bincode2D.html","id":null,"dir":"Reference","previous_headings":"","what":"Retain bin code data — .bincode2D","title":"Retain bin code data — .bincode2D","text":"Retain bin code data","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/dot-bincode2D.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retain bin code data — .bincode2D","text":"","code":".bincode2D(x, y, bin1, bin2)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/dot-bincode2D.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retain bin code data — .bincode2D","text":"x numeric vector binning performed number bin1 y numeric vector binning performed number bin2 bin1 number bin x bin2 number bin y","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/dot-bincode2D.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retain bin code data — .bincode2D","text":"list object containing bin matrices list counts matrices list","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":null,"dir":"Reference","previous_headings":"","what":"Get CNN Images from TockyPrepData Object — getImages","title":"Get CNN Images from TockyPrepData Object — getImages","text":"Retrieves CNN images data TockyPrepData object prints diagnostic information image data structure.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get CNN Images from TockyPrepData Object — getImages","text":"","code":"getImages(x)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get CNN Images from TockyPrepData Object — getImages","text":"x TockyPrepData object containing processed CNN images data. object must already undergone ImageConversion.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get CNN Images from TockyPrepData Object — getImages","text":"CNN images data stored object's TockyCNNimages slot. returned value maintains original structure slot, typically including: Image arrays first element Sample definitions second element Variables used third element","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get CNN Images from TockyPrepData Object — getImages","text":"function performs following actions: Checks TockyCNNimages slot contains data Prints diagnostic information including: Dimensions image arrays Variables used analysis Sample definitions","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/getImages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get CNN Images from TockyPrepData Object — getImages","text":"","code":"if (FALSE) { # \\dontrun{ # After successful ImageConversion: images_data <- getCNNimages(tocky_prep_object) dim(images_data[[1]])  # Access image array dimensions } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data into image — image_conversion","title":"Convert data into image — image_conversion","text":"Convert data image","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data into image — image_conversion","text":"","code":"image_conversion(data, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data into image — image_conversion","text":"data data frame n_resolution number bins","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data into image — image_conversion","text":"list object containing bin matrices list counts matrices list","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data into image — image_conversion","text":"","code":"if (FALSE) { # \\dontrun{ out <- image_conversion(data) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data into image — image_conversion_raw","title":"Convert data into image — image_conversion_raw","text":"Convert data image","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data into image — image_conversion_raw","text":"","code":"image_conversion_raw(data, selected_markers, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data into image — image_conversion_raw","text":"data data frame selected_markers character vector length two defining  marker data converted 2D images. n_resolution number bins used. default 100, .e. resolution output images 100 x 100.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data into image — image_conversion_raw","text":"list object containing bin matrices list counts matrices list","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/image_conversion_raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data into image — image_conversion_raw","text":"","code":"if (FALSE) { # \\dontrun{ out <- image_conversion_raw(data) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/inverseGradCAM.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","title":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","text":"Identifies significant feature cells using Grad-CAM data either visualization (gating mode) lightweight operation using pre-converted images (base mode).","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/inverseGradCAM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","text":"","code":"inverseGradCAM(   x = NULL,   results = NULL,   feature_matrix,   mode = c(\"gating\", \"base\"),   percentile = 0.9,   n_resolution = 100,   transpose = TRUE,   filename = NULL,   ncol = 2,   nrow = 2 )"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/inverseGradCAM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","text":"x TockyPrepData object (required \"gating\" mode) results convert_to_image output (required \"base\" mode) feature_matrix Feature intensity matrix Grad-CAM analysis mode Operation mode (\"gating\" visualization, \"base\" lightweight analysis) percentile Significance threshold percentile (0-1). NULL, grad-CAM values returned, instead feature cell designation. n_resolution Binning resolution (\"gating\" mode ) transpose Logical Whether tranpose feature_matrix input. Note TockyConvNetPy output Grad-CAM matrix feature_matrix typically needs transposed. default TRUE. filename Optional PDF output path (\"gating\" mode ) ncol number columns output plot nrow number rows output plot","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/inverseGradCAM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","text":"binary numeric vector (1/0) feature cells. `percentile = NULL`, grad-CAM values returned numeric vector.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/inverseGradCAM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrated Grad-CAM Feature Cell Identification — inverseGradCAM","text":"","code":"if (FALSE) { # \\dontrun{ # Gating mode with visualization out <- inverseGradCAM(mode = \"gating\", x = prep_data,                          feature_matrix = cam_matrix, filename = \"output.pdf\")  # Base mode with pre-converted results img_data <- convert_to_image(merged_data) out <- inverseGradCAM(mode = \"base\", results = img_data,                          feature_matrix = cam_matrix) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize an array — normalize_array","title":"Normalize an array — normalize_array","text":"function normalizes 3-dimensional array processing first layer, multiplying element 10,000 dividing sum first layer. replicates normalized first layer additional layers exist.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize an array — normalize_array","text":"","code":"normalize_array(array, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize an array — normalize_array","text":"array 3-dimensional array normalized. n_resolution number bins used. default 100, .e. resolution output images 100 x 100.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize an array — normalize_array","text":"normalized 3-dimensional array.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_array.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize an array — normalize_array","text":"","code":"if (FALSE) { # \\dontrun{ array <- array(1:24, c(2, 2, 3)) normalize_array(array) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize a matrix — normalize_matrix","title":"Normalize a matrix — normalize_matrix","text":"function normalizes matrix multiplying element 10,000 dividing sum matrix.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize a matrix — normalize_matrix","text":"","code":"normalize_matrix(matrix, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize a matrix — normalize_matrix","text":"matrix numeric matrix normalized. n_resolution number bins used. default 100, .e. resolution output images 100 x 100.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize a matrix — normalize_matrix","text":"normalized matrix.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/normalize_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize a matrix — normalize_matrix","text":"","code":"if (FALSE) { # \\dontrun{ matrix <- matrix(1:4, 2, 2) normalize_matrix(matrix) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data into pixel-style data — pixel_2d","title":"Convert data into pixel-style data — pixel_2d","text":"Convert data pixel-style data","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data into pixel-style data — pixel_2d","text":"","code":"pixel_2d(data, bin_edges_Angle, bin_edges_Intensity, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data into pixel-style data — pixel_2d","text":"data data frame bin_edges_Angle numeric vector defining bin adges Angle bin_edges_Intensity numeric vector defining bin adges Angle n_resolution number bins","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data into pixel-style data — pixel_2d","text":"list object containing bin matrices list counts matrices list","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_inverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse 2D Pixel Mapping — pixel_2d_inverse","title":"Inverse 2D Pixel Mapping — pixel_2d_inverse","text":"internal function maps matrix indices back corresponding angle intensity intervals based provided bin edges. primarily used interpret indices 2D histogram matrix representation back original data space.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_inverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse 2D Pixel Mapping — pixel_2d_inverse","text":"","code":"pixel_2d_inverse(row_idx, col_idx, bin_edges_Angle, bin_edges_Intensity)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_inverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse 2D Pixel Mapping — pixel_2d_inverse","text":"row_idx integer representing row index matrix, corresponding specific intensity bin. col_idx integer representing column index matrix, corresponding specific angle bin. bin_edges_Angle numeric vector bin edges angle dimension. length vector one number angle bins. bin_edges_Intensity numeric vector bin edges intensity dimension. length vector one number intensity bins.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_inverse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse 2D Pixel Mapping — pixel_2d_inverse","text":"list containing two elements: angle_interval intensity_interval. element numeric vector length 2, representing lower upper bounds interval angle intensity, respectively.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_inverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse 2D Pixel Mapping — pixel_2d_inverse","text":"","code":"if (FALSE) { # \\dontrun{ pixel_2d_inverse(10, 20, bin_edges_Angle, bin_edges_Intensity) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data into pixel-style data — pixel_2d_raw","title":"Convert data into pixel-style data — pixel_2d_raw","text":"Convert data pixel-style data","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data into pixel-style data — pixel_2d_raw","text":"","code":"pixel_2d_raw(   data,   bin_edges_Angle,   bin_edges_Intensity,   n_resolution = 100,   selected_markers )"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data into pixel-style data — pixel_2d_raw","text":"data data frame bin_edges_Angle numeric vector defining bin adges Angle bin_edges_Intensity numeric vector defining bin adges Angle n_resolution number bins selected_markers character vector length two defining  marker data converted 2D images.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/pixel_2d_raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data into pixel-style data — pixel_2d_raw","text":"list object containing bin matrices list counts matrices list","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureCells.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Plots for Analysing Feature Cell Abundance — plotGradCAMFeatureCells","title":"Generate Plots for Analysing Feature Cell Abundance — plotGradCAMFeatureCells","text":"function processes clustering results, plots cluster, overlays cluster's convex hull. adaptable number cell_cluster_id.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureCells.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Plots for Analysing Feature Cell Abundance — plotGradCAMFeatureCells","text":"","code":"plotGradCAMFeatureCells(   x,   feature_matrix,   p_adjust_method = \"BH\",   ncol = 3,   min_cells = 10,   title = \"GradCAM Feature Cells\",   Timer_positive = TRUE,   ylim = NULL )"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureCells.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Plots for Analysing Feature Cell Abundance — plotGradCAMFeatureCells","text":"x TockyPrepData object (required \"gating\" mode) feature_matrix Feature intensity matrix Grad-CAM analysis p_adjust_method method p-value adjustment multiple testing using Mann Whitney. clusteringFeatureCells cen used. ncol Number columns output figure panel. min_cells Numeric. minimum nunmber cells within cluster analysed. default 10. title character title plot. Timer_positive Logical. Whether remove Timer negative cells. ylim Optional. numeric vector length 2 specifying ylim.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureCells.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Plots for Analysing Feature Cell Abundance — plotGradCAMFeatureCells","text":"","code":"if (FALSE) { # \\dontrun{   data <- data.frame(Angle = runif(100), Intensity = runif(100))   cell_cluster_id <- dbscan(data, eps = 0.1, minPts = 5)$cluster   plotGradCAMFeatureCells(data, cell_cluster_id) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureMFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","title":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","text":"Generate boxplot MFI (median fluorescence intensity) Grad-CAM feature cells, Timer+ cells, Timer negative cells following inverseGradCAM.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureMFI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","text":"","code":"plotGradCAMFeatureMFI(   x,   feature_vector,   group = NULL,   select = FALSE,   variables = NULL,   title = \"GradCAM Feature Cells\" )"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureMFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","text":"x `TockyPrepData` object containing original flow cytometry data. feature_vector vector output inverseGradCAM. group character vector specifying group(s) use analysis. NULL, groups used. select logical indicating whether allow interactive selection variables analysis. variables character vector specifying variables analyze. used `select` TRUE. title character title plot.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureMFI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","text":"list containing following elements:   * `plot`: ggplot object boxplot.   * `summary_data`: data frame containing summarized data used create plot.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotGradCAMFeatureMFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a boxplot of MFI (median fluorescence intensity) for Grad-CAM feature cells, other Timer+ cells, and Timer negative cells following inverseGradCAM. — plotGradCAMFeatureMFI","text":"","code":"if (FALSE) { # \\dontrun{   feature_matrix <- read.csv('heatmap.csv') plotGradCAMFeatureMFI(x, feature_matrix) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotInverseGradCAM.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","title":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","text":"function obtains GradCAM heatmap values cell original flow cytometric space, mapping `Angle` `Intensity` image dimensions (pixels) back corresponding cells.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotInverseGradCAM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","text":"","code":"plotInverseGradCAM(   x,   feature_matrix,   xaxis = \"Red_log\",   yaxis = \"Blue_log\",   xlim = NULL,   ylim = NULL,   title = \"GradCAM\",   color_bar = TRUE,   n_resolution = 100,   transpose = TRUE )"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotInverseGradCAM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","text":"x `TockyPrepData` object containing original flow cytometry data. feature_matrix 100 x 100 matrix representing GradCAM output. xaxis name dataframe column used x-axis plot (default 'Red_log'). yaxis name dataframe column used y-axis plot (default 'Blue_log'). xlim Optional vector length 2 defining x-axis limits. ylim Optional vector length 2 defining y-axis limits. title Character string specifying title plot. color_bar Logical indicating whether include color bar plot (default TRUE). n_resolution Binning resolution. default 100. transpose Logical Whether tranpose feature_matrix input. Note TockyConvNetPy output Grad-CAM matrix feature_matrix typically needs transposed. default TRUE.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotInverseGradCAM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","text":"Invisibly returns unmodified `TockyPrepData` object.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/plotInverseGradCAM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot GradCAM (or Heatmap) Values in Original Flow Cytometry Plot — plotInverseGradCAM","text":"","code":"if (FALSE) { # \\dontrun{   feature_matrix <- read.csv('heatmap.csv')   par(mfrow= c(1,2))   plotInverseGradCAM(x, feature_matrix, color_bar = TRUE) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_array_colour.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape a list of color matrices into an array — reshape_array_colour","title":"Reshape a list of color matrices into an array — reshape_array_colour","text":"function reshapes list color matrices (representing different image) 4-dimensional array, preserving color channels.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_array_colour.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape a list of color matrices into an array — reshape_array_colour","text":"","code":"reshape_array_colour(data_list)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_array_colour.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape a list of color matrices into an array — reshape_array_colour","text":"data_list list numeric matrices color dimensions reshaped.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_array_colour.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape a list of color matrices into an array — reshape_array_colour","text":"4-dimensional array.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_array_colour.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape a list of color matrices into an array — reshape_array_colour","text":"","code":"if (FALSE) { # \\dontrun{ data_list <- list(array(1:30000, c(100, 100, 3)), array(301:60000, c(100, 100, 3))) reshape_array_colour(data_list) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape a list of matrices into an array — reshape_data","title":"Reshape a list of matrices into an array — reshape_data","text":"function reshapes list matrices 4-dimensional array, assuming matrix represents single layer image similar data structure.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape a list of matrices into an array — reshape_data","text":"","code":"reshape_data(data_list, n_resolution = 100)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape a list of matrices into an array — reshape_data","text":"data_list list numeric matrices reshaped. n_resolution number bins used. default 100, .e. resolution output images 100 x 100.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape a list of matrices into an array — reshape_data","text":"4-dimensional array.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/reshape_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape a list of matrices into an array — reshape_data","text":"","code":"if (FALSE) { # \\dontrun{ data_list <- list(matrix(1:10000, 100, 100), matrix(101:20000, 100, 100)) reshape_data(data_list) } # }"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":null,"dir":"Reference","previous_headings":"","what":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"Export CNN images data TockyPrepData object prints diagnostic information image data structure.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"","code":"writeImages(x, numpy = TRUE)"},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"x TockyPrepData object containing processed CNN images data. object must already undergone ImageConversion. numpy Logical. Whether export data numpy format. FALSE, csv files exported instead.","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"CNN images data stored object's TockyCNNimages slot. returned value maintains original structure slot, typically including: Image arrays first element Sample definitions second element Variables used third element","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"function performs following actions: Checks TockyCNNimages slot contains data Prints diagnostic information including: Dimensions image arrays Variables used analysis Sample definitions","code":""},{"path":"https://MonoTockyLab.github.io/TockyConvNetR/reference/writeImages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export TockyCNN Image Data from TockyPrepData Object — writeImages","text":"","code":"if (FALSE) { # \\dontrun{ # After successful ImageConversion: images_data <- getCNNimages(tocky_prep_object) dim(images_data[[1]])  # Access image array dimensions } # }"}]
